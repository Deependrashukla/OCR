{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP7qY0qz0bLcB1Z/xEg+R2h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deependrashukla/OCR/blob/main/Image_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **What libraries we used :**\n",
        "[Refference Article about code and explanation](https://www.analyticsvidhya.com/blog/2021/06/optical-character-recognitionocr-with-tesseract-opencv-and-python/)\n",
        "\n",
        " we have gained a solid understanding of Optical Character Recognition (OCR) and learned how to use libraries like OpenCV and Tesseract to extract text from images. We explored practical applications like **building word clouds** (kind of ploting graph) and creating spoken audio from text. For more advanced tasks like object detection and accurate character recognition in diverse image scenarios, powerful techniques like neural networks, bounding boxes, and object detection templates can be employed, regardless of the specific framework used (e.g., TensorFlow, PyTorch)."
      ],
      "metadata": {
        "id": "w2vO-frLr-DH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "# folderPath = \"Reviews\"\n",
        "# myRevList = os.listdir(folderPath)"
      ],
      "metadata": {
        "id": "MJ_SKXhq__9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytesseract\n",
        "!apt-get install tesseract-ocr -y"
      ],
      "metadata": {
        "id": "igA-LfMqAE0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Binarization\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image as im\n",
        "from scipy.ndimage import interpolation as inter\n",
        "# input_file = \"/content/WhastsApp Image 2024-06-07 at 16.11.28.jpeg\"\n",
        "# img = im.open(input_file)\n",
        "# # convert to binary\n",
        "# wd, ht = img.size\n",
        "# pix = np.array(img.convert('1').getdata(), np.uint8)\n",
        "# bin_img = 1 - (pix.reshape((ht, wd)) / 255.0)\n",
        "# plt.imshow(bin_img, cmap='gray')\n",
        "# plt.savefig('binary.png')"
      ],
      "metadata": {
        "id": "cWF15h_twJWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image as im\n",
        "from scipy.ndimage import interpolation as inter\n",
        "import cv2  # Import OpenCV\n",
        "\n",
        "input_file = \"/content/Screenshot 2024-06-20 155142.png\"\n",
        "img = im.open(input_file)\n",
        "# Convert the image to grayscale\n",
        "gray = np.array(img.convert('L'))\n",
        "\n",
        "# Apply adaptive thresholding\n",
        "bin_img = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
        "bin_img = 1 - (bin_img / 255.0)  # Invert the image to match previous format (white text on black background)\n",
        "\n",
        "plt.imshow(bin_img, cmap='gray')\n",
        "plt.savefig('adaptive_binary.png')\n",
        "\n"
      ],
      "metadata": {
        "id": "YWEbblMlU483"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bin_img = image\n",
        "def find_score(arr, angle):\n",
        "    data = inter.rotate(arr, angle, reshape=False, order=0)\n",
        "    hist = np.sum(data, axis=1)\n",
        "    score = np.sum((hist[1:] - hist[:-1]) ** 2)\n",
        "    return hist, score\n",
        "\n",
        "delta = 1\n",
        "limit = 5\n",
        "angles = np.arange(-limit, limit + delta, delta)\n",
        "scores = []\n",
        "for angle in angles:\n",
        "    hist, score = find_score(bin_img, angle)\n",
        "    scores.append(score)\n",
        "\n",
        "best_score = max(scores)\n",
        "best_angle = angles[scores.index(best_score)]\n",
        "\n",
        "# Correct skew\n",
        "data = inter.rotate(bin_img, best_angle, reshape=False, order=0)\n",
        "img = im.fromarray((255 * data).astype(\"uint8\")).convert(\"RGB\")\n",
        "# img.save('skew_corrected.png')\n",
        "plt.imshow(img, cmap='gray')\n"
      ],
      "metadata": {
        "id": "XJDzORD6_ZAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### noise removal\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "# Reading image from folder where it is stored\n",
        "img = cv2.imread('/content/binary.png')\n",
        "# denoising of image saving it into dst image\n",
        "dst = cv2.fastNlMeansDenoisingColored(img, None, 10, 10, 7, 15)\n",
        "# Plotting of source and destination image\n",
        "plt.subplot(121), plt.imshow(img)\n",
        "plt.subplot(122), plt.imshow(dst)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "cDaUzM8N-xnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**conversion of pdf to image !**"
      ],
      "metadata": {
        "id": "Ao6nLBbJXScs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y poppler-utils\n",
        "!pip install pdf2image"
      ],
      "metadata": {
        "id": "C4Re9VkdDD6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pdf2image import convert_from_path\n",
        "\n",
        "def process_pdf(pdf_path):\n",
        "    # Convert PDF to high-resolution images\n",
        "    pages = convert_from_path(pdf_path, dpi=300)\n",
        "    image_paths = []\n",
        "    for i, page in enumerate(pages):\n",
        "        image_path = f\"/tmp/page_{i}.png\"\n",
        "        page.save(image_path, 'PNG')\n",
        "        image_paths.append(image_path)\n",
        "    return image_paths\n",
        "\n",
        "process_pdf('/content/EAadhaar_dama_padmavathi.pdf')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hlrwCO7CvNM",
        "outputId": "89917bfd-ea13-4a18-afab-5bce9bbeaffb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/tmp/page_0.png']"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**average and weightage method for grayscaling**"
      ],
      "metadata": {
        "id": "TbfnVzkpYKoj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the image\n",
        "image_path = \"/content/abhishek.jpeg\"\n",
        "image = cv2.imread(image_path)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n"
      ],
      "metadata": {
        "id": "glM68REKP487"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def avg_grayscale(image):\n",
        "  rows, cols, _  =  image.shape\n",
        "\n",
        "  for i in range(rows):\n",
        "    for j in range(cols):\n",
        "      pixel = image[i,j]\n",
        "      image[i,j] = int(sum(pixel)/len(pixel))\n",
        "\n",
        "  return image\n",
        "\n",
        "gray_image = avg_grayscale(image)\n",
        "plt.imshow(gray_image)\n",
        "\n",
        "# inversion of color\n",
        "# plt.imshow(255-image)"
      ],
      "metadata": {
        "id": "DHPF8NwS3BTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# weightage method\n",
        "def wght_grayscale(image):\n",
        "  rows, cols, _  =  image.shape\n",
        "\n",
        "  for i in range(rows):\n",
        "    for j in range(cols):\n",
        "      pixel = image[i,j]\n",
        "      image[i,j] = 255 - (0.21*pixel[0] + 0.72*pixel[1] + 0.07*pixel[2]) # inverting color highlights the text in image.\n",
        "\n",
        "  return image\n",
        "\n",
        "bin_image = wght_grayscale(image)\n",
        "plt.imshow(bin_image)"
      ],
      "metadata": {
        "id": "QnqJczTqUSti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/firdos.png\"\n",
        "image = cv2.imread(image_path)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "# weightage method\n",
        "def wght_grayscale(image):\n",
        "  rows, cols, _  =  image.shape\n",
        "\n",
        "  for i in range(rows):\n",
        "    for j in range(cols):\n",
        "      pixel = image[i,j]\n",
        "      x = 255 - (0.21*pixel[0] + 0.72*pixel[1] + 0.07*pixel[2]) # inverting color highlights the text in image.\n",
        "      image[i,j] = 0 if x < 110 else 255\n",
        "\n",
        "  return image\n",
        "\n",
        "bin_image = wght_grayscale(image)\n",
        "plt.imshow(bin_image)"
      ],
      "metadata": {
        "id": "LvnPI8ObWFbN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}